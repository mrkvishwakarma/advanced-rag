{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG Exercise\n",
    "\n",
    "Build a simple RAG flow to recommend oldie movies based on user's requests. The dataset includes 5,000 movies descriptions. In the exercise, you will learn to add a filter to the semantic retrieval and the data columns sent to the generation step.\n",
    "\n",
    "Fill in the empty cells, and answer the questions on the course site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich_theme_manager import Theme, ThemeManager\n",
    "import pathlib\n",
    "\n",
    "theme_dir = pathlib.Path(\"../themes\")\n",
    "theme_manager = ThemeManager(theme_dir=theme_dir)\n",
    "dark = theme_manager.get(\"dark\")\n",
    "\n",
    "# Create a console with the dark theme\n",
    "console = Console(theme=dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Movie Dataset\n",
    "\n",
    "We will load the moview dataset from Hugging Face hub in:\n",
    "https://huggingface.co/datasets/AiresPucrs/tmdb-5000-movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode using Vector Embedding\n",
    "\n",
    "We will use one of the popular open source vector databases, [Qdrant](https://qdrant.tech/), and one of the popular embedding encoder and text transformer libraries, [SentenceTransformer](https://sbert.net/).\n",
    "\n",
    "This time we will use the following sentence similarity model:\n",
    "https://huggingface.co/sentence-transformers/all-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models, QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# create the vector database client\n",
    "qdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance\n",
    "\n",
    "# Create the embedding encoder\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection to store the wine rating data\n",
    "collection_name=\"movies\"\n",
    "\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=encoder.get_sentence_embedding_dimension(), # Vector size is defined by used model\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data into the vector database\n",
    "\n",
    "We will use the collection that we created above, to go over all the rows and encode the `overview` column of the wine dataset, encode it with the encoder into embedding vector, and store it in the vector database. Please use the index of the movie from the dataset (`id` column) as the `id` in the vector index.\n",
    "\n",
    "Please note that some of the rows are missing the `overview`. You should ignore them and not upload them into the vector database index.\n",
    "\n",
    "This step will take a few seconds (less than a minute on my laptop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize!\n",
    "qdrant.upload_points(\n",
    "    collection_name=collection_name,\n",
    "    points=[\n",
    "### YOUR CODE HERE ###\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(\n",
    "    qdrant\n",
    "    .get_collection(\n",
    "        collection_name=collection_name\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **R**etrieve sematically relevant data based on user's query\n",
    "\n",
    "Once the data is loaded into the vector database and the indexing process is done, we can start using our simple RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Love story between an Asian king and European teacher\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the user's query\n",
    "\n",
    "We will use the same encoder that we used to encode the document data to encode the query of the user. \n",
    "This way we can search results based on semantic similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = encoder.encode(user_prompt).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create filter on the results\n",
    "\n",
    "We only want movies from the '90s. Please create a filter base on the `release_date` column. Check the Qdrant documentation in: https://qdrant.tech/documentation/concepts/filtering/#datetime-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "query_filter= models.Filter(\n",
    "### YOUR CODE HERE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search similar rows\n",
    "\n",
    "We can now take the embedding encoding of the user's query and use it to find similar rows in the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search time for awesome wines!\n",
    "\n",
    "hits = qdrant.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_vector,\n",
    "    limit=1,\n",
    "    query_filter=query_filter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.text import Text\n",
    "from rich.table import Table\n",
    "\n",
    "table = Table(title=\"Retrieval Results\", show_lines=True)\n",
    "\n",
    "table.add_column(\"ID\", style=\"#e0e0e0\")\n",
    "table.add_column(\"Original Title\", style=\"#e0e0e0\")\n",
    "table.add_column(\"Overview\", style=\"bright_red\")\n",
    "table.add_column(\"Score\", style=\"#89ddff\")\n",
    "\n",
    "for hit in hits:\n",
    "    table.add_row(\n",
    "        str(hit.payload[\"id\"]),\n",
    "        hit.payload[\"original_title\"],\n",
    "        f'{hit.payload[\"overview\"]}',\n",
    "        f\"{hit.score:.4f}\"\n",
    "    )\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **A**ugment the prompt to the LLM with retrieved data\n",
    "\n",
    "In our simple example, we will simply take the top result and use it in the prompt to the generation LLM. We will filter some of the columns and keep only the following:\n",
    "* `original_title`\n",
    "* `title`\n",
    "* `overview`\n",
    "* `release_date`\n",
    "* `popularity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a variable to hold the search results with specific fields\n",
    "search_results = [\n",
    "    {\n",
    "### YOUR CODE HERE\n",
    "    } for hit in hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **G**enerate reply to the user's query\n",
    "\n",
    "We will use GPT-4 from [OpenAI](https://platform.openai.com/docs/models). Please write the prompt to instruct the LLM to write the recommendations based on the search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffff00; text-decoration-color: #ffff00\">╭────────────────────────────────────── Movie Recommendation with Retrieval ──────────────────────────────────────╮</span>\n",
       "<span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span>                                                                                                                 <span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span>\n",
       "<span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span> The movie you're looking for is 'Anna and the King' (1999). The film depicts the unique relationship between    <span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span>\n",
       "<span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span> the King of Siam (now Thailand) and a widowed British school teacher Anna Leonowens during the 1860's. Anna     <span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span>\n",
       "<span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span> teaches the king's many children and slowly develops a romantic yet controversial relationship with the king    <span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span>\n",
       "<span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span> himself. This beautifully crafted story takes you through a rollercoaster of emotions, intrigue, and discovery  <span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span>\n",
       "<span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span> of new cultures. You're sure to enjoy it.                                                                       <span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span>\n",
       "<span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span>                                                                                                                 <span style=\"color: #ffff00; text-decoration-color: #ffff00\">│</span>\n",
       "<span style=\"color: #ffff00; text-decoration-color: #ffff00\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[93m╭─\u001b[0m\u001b[93m─────────────────────────────────────\u001b[0m\u001b[93m Movie Recommendation with Retrieval \u001b[0m\u001b[93m─────────────────────────────────────\u001b[0m\u001b[93m─╮\u001b[0m\n",
       "\u001b[93m│\u001b[0m                                                                                                                 \u001b[93m│\u001b[0m\n",
       "\u001b[93m│\u001b[0m The movie you're looking for is 'Anna and the King' (1999). The film depicts the unique relationship between    \u001b[93m│\u001b[0m\n",
       "\u001b[93m│\u001b[0m the King of Siam (now Thailand) and a widowed British school teacher Anna Leonowens during the 1860's. Anna     \u001b[93m│\u001b[0m\n",
       "\u001b[93m│\u001b[0m teaches the king's many children and slowly develops a romantic yet controversial relationship with the king    \u001b[93m│\u001b[0m\n",
       "\u001b[93m│\u001b[0m himself. This beautifully crafted story takes you through a rollercoaster of emotions, intrigue, and discovery  \u001b[93m│\u001b[0m\n",
       "\u001b[93m│\u001b[0m of new cultures. You're sure to enjoy it.                                                                       \u001b[93m│\u001b[0m\n",
       "\u001b[93m│\u001b[0m                                                                                                                 \u001b[93m│\u001b[0m\n",
       "\u001b[93m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from rich.panel import Panel\n",
    "\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "### YOUR CODE HERE ###\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_text = Text(completion.choices[0].message.content)\n",
    "styled_panel = Panel(\n",
    "    response_text,\n",
    "    title=\"Movie Recommendation with Retrieval\",\n",
    "    expand=False,\n",
    "    border_style=\"bright_yellow\",\n",
    "    padding=(1, 1)\n",
    ")\n",
    "\n",
    "console.print(styled_panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
